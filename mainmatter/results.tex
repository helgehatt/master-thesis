\chapter{Results}\label{ch:Results}

This chapter presents the results of applying the methodology in \Cref{ch:Method} to the datasets described in \Cref{ch:Data}. The synthetic data is examined first, including comparisons of the static latent space model, the diffusion model and autoregressive models of various order. The models are evaluated in terms of AUC scores on test data, as well as the learned latent representation of the underlying network. 

The two real-life networks considered are directed and aggregated to a daily basis, having an expected seasonality of seven, corresponding to a week. Hence, the datasets are modeled using an additional autoregressive model of order seven. The EU email dataset exhibits a distinct periodic pattern, in which the email activity is much higher on weekdays opposed to weekends. Meanwhile, the cropped UC messaging dataset is quite irregular and sparse, having significantly less activity with twice the number of nodes. As a result, the dataset is likely more difficult to accurately predict.
% Regardless, the unusual behavior can be used to more thoroughly analyze the effect of diffusion penalties.

Each figure and animation include several labels in their captions, describing which model is used, whether it is undirected or directed, the dimensionality of the latent space and which cost function is used to penalize the addition of diffusion. 
\Cref{AbbrvModels,AbbrvParams,AbbrvPenalties} list the abbreviations used for the different models, model parameters and diffusion penalties, respectively.
\xtab[H]{\xdouble[0.6]
    {\xtex{AbbrvModels}[Models]}
    {\xtex{AbbrvParams}[Parameters]}
}
\xwrap[table]{\xtex{AbbrvPenalties}[Penalties]}[0.4\textwidth]
There is a large number of different models to consider due to the number of ways to combine model types, parameters and diffusion penalties. First of all, there are three types of models, where the autoregressive model can have an arbitrary order. Each of these models can either be directed or undirected, and with an arbitrary dimensionality.
Furthermore, there are four approaches to penalizing diffusion, which quickly gives rise to more than a hundred model variants using only three orders of $p$ and three values for $k$. Hence, testing all combinations is not feasible, especially considering that each model should preferably be run multiple times to ensure a maximal convergence limit. The solution to the combinatorial explosion, is to make conscious decisions on which models, parameters and penalties to select for each individual dataset.


\section{Synthetic Data}

    The synthetic data is comprised of 30 nodes over 100 time steps, and is split into a training set of 80 time steps and a test set with the remaining 20. Knowing that the datasets are undirected and two-dimensional, directed models and models of higher dimensions are not considered. A trained model of correct type and order is expected to be able to accurately capture the underlying true model.
    
    With a limited number of entities in the synthetic datasets, each batch include all nodes, where the loss of a batch is computed 80 times an epoch, once for each time step in the training data. Validation occurs every ten epochs, computing the AUC scores for each individual time step as well as average training and test AUCs.
    The optimization procedure uses an early stopping criteria, where the evaluation metric is the equally weighted sum of average training and test AUCs. Termination occurs when the metric increased by less than 0.01 over three validation steps (30 epochs). In case of the autoregressive models, the training does not stop, but continues to the next optimization block as described in \Cref{sec:pyimpl-positions} on warm starting.
    
    % The models are trained for a minimum of 200 epochs, using an early stopping criteria to decide when the training has converged. The requirement is an increase in test AUC of 0.001 over 30 epochs, terminating the optimization procedure if this criteria is not met. 
    
    % When the training stops for the first time, the number of time steps to include in a single step of the optimizer increases from 1 to 10, continuing training with accumulated gradients to further improve performance. Since the change in diffusion rate and AR coefficients has an impact on all time steps, optimizing for a single time step can result in a negative impact overall. Hence, accumulating the gradients makes the training more stable, however it also makes the optimizer more prone to end in local minima, and including more than 10 time steps has not proved to benefit performance.

    \subsection{Static Data}
    
        \Cref{Results/Static/Train/StaticModel-AR(1)-Undirected-NoLoss} depicts the convergence of the static latent space model, showing the average loss per batch (upper left), the average training and test AUC scores (lower left) as well as the model's current AUC scores for each individual time step (right). The convergence is shown for selected models, especially to provide insight into how the different types of models converge, and how the convergence is affected by for instance the use of different diffusion penalties.
    
        \xfig[H]{\xanim{Results/Static/Train/StaticModel-AR(1)-Undirected-NoLoss}[LSM | U | K(2) | NL]}
        
        The next page includes several figures and animations visualizing the true network and the latent representations generated by the different models. The goal of the models is to mimic the true network as well as possible, giving rise to accurate test predictions. The models produce link probabilities, and not actual binary predictions, such that the networks are depicted with edges of various grey tones, where a darker edge represents a higher link probability. This applies to the true network as well, illustrating the underlying link probabilities from which the links are drawn. The nodes are labeled with numbers, allowing a direct comparison of closeness between true positions and latent space positions.
        
        The synthetic data is concluded with a comparison of test ROC curves, and the corresponding AUC scores in the legend, for each individual model for each dataset. The static latent space model is expected to perform slightly better than the other models on the static data, as the dynamic models are likely to provide an overcomplicated fit. However, the dynamic and periodic data require the additional complexity, where the static model is expected to perform significantly worse.
        
        \xfig[H]{\xdouble
            {\ximg{Results/Static/Proba/StaticModel-AR(1)-Undirected-True}[True]}
            {\ximg{Results/Static/Proba/StaticModel-AR(1)-Undirected-NoLoss}[LSM | U | K(2) | NL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Static/Proba/DiffusionModel-AR(1)-Undirected-NoLoss}[DFM | U | K(2) | NL]}
            {\xanim{Results/Static/Proba/AutoregressiveModel-AR(1)-Undirected-NoLoss}[AR(1) | U | K(2) | NL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Static/Proba/AutoregressiveModel-AR(2)-Undirected-NoLoss}[AR(2) | U | K(2) | NL]}
            {\xanim{Results/Static/Proba/AutoregressiveModel-AR(3)-Undirected-NoLoss}[AR(3) | U | K(2) | NL]}
        }
    
    
    \subsection{Dynamic Data}
        
        \xfig[H]{\xdouble
            {\xanim{Results/Dynamic/Train/DiffusionModel-AR(1)-Undirected-NoLoss}[DFM | U | K(2) | NL]}
            {\xanim{Results/Dynamic/Space/DiffusionModel-AR(1)-Undirected-NoLoss}[DFM | U | K(2) | NL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Dynamic/Train/DiffusionModel-AR(1)-Undirected-GaussianLoss}[DFM | U | K(2) | GL]}
            {\xanim{Results/Dynamic/Space/DiffusionModel-AR(1)-Undirected-GaussianLoss}[DFM | U | K(2) | GL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Dynamic/Train/DiffusionModel-AR(1)-Undirected-GaussianLossNoVar}[DFM | U | K(2) | GNV]}
            {\xanim{Results/Dynamic/Space/DiffusionModel-AR(1)-Undirected-GaussianLossNoVar}[DFM | U | K(2) | GNV]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Dynamic/Proba/DiffusionModel-AR(1)-Undirected-True}[True]}
            {\ximg {Results/Dynamic/Proba/StaticModel-AR(1)-Undirected-NoLoss}[LSM | U | K(2) | NL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Dynamic/Proba/DiffusionModel-AR(1)-Undirected-GaussianLossNoVar}[DFM | U | K(2) | GNV]}
            {\xanim|6|{Results/Dynamic/Proba/AutoregressiveModel-AR(1)-Undirected-GaussianLossNoVar}[AR(1) | U | K(2) | GNV]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/Dynamic/Proba/AutoregressiveModel-AR(2)-Undirected-GaussianLossNoVar}[AR(2) | U | K(2) | GNV]}
            {\xanim|6|{Results/Dynamic/Proba/AutoregressiveModel-AR(3)-Undirected-GaussianLossNoVar}[AR(3) | U | K(2) | GNV]}
        }

    \subsection{Periodic Data}
        
        \xfig[H]{\xdouble
            {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(3)-Undirected-NoLoss}[AR(3) | U | K(2) | NL]}
            {\xanim|3|{Results/Periodic/Space/AutoregressiveModel-AR(3)-Undirected-NoLoss}[AR(3) | U | K(2) | NL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(3)-Undirected-GaussianLoss}[AR(3) | U | K(2) | GL]}
            {\xanim|3|{Results/Periodic/Space/AutoregressiveModel-AR(3)-Undirected-GaussianLoss}[AR(3) | U | K(2) | GL]}
        }\xfig[H]{\xdouble
            {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(3)-Undirected-GaussianLossNoVar}[AR(3) | U | K(2) | GNV]}
            {\xanim|3|{Results/Periodic/Space/AutoregressiveModel-AR(3)-Undirected-GaussianLossNoVar}[AR(3) | U | K(2) | GNV]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/Periodic/Proba/AutoregressiveModel-AR(3)-Undirected-True}[True]}
            {\ximg{Results/Periodic/Proba/StaticModel-AR(1)-Undirected-NoLoss}[LSM | U | K(2) | NL]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/Periodic/Proba/DiffusionModel-AR(1)-Undirected-GaussianLoss}[DFM | U | K(2) | GL]}
            {\xanim|6|{Results/Periodic/Proba/AutoregressiveModel-AR(1)-Undirected-GaussianLoss}[AR(1) | U | K(2) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/Periodic/Proba/AutoregressiveModel-AR(2)-Undirected-GaussianLoss}[AR(2) | U | K(2) | GL]}
            {\xanim|3|{Results/Periodic/Proba/AutoregressiveModel-AR(3)-Undirected-GaussianLoss}[AR(3) | U | K(2) | GL]}
        }

        % \begin{figure}[!htb]
        %     \floatname{animation}{A}
        %     \xdicol{
        %         \xtricol
        %             {\xtrirow
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(1)-Undirected-NoLoss}[AR(1) | NL]}
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(2)-Undirected-NoLoss}[AR(2) | NL]}
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(3)-Undirected-NoLoss}[AR(3) | NL]}
        %             }{\xtrirow
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(1)-Undirected-GaussianLoss}[AR(1) | GL]}
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(2)-Undirected-GaussianLoss}[AR(2) | GL]}
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(3)-Undirected-GaussianLoss}[AR(3) | GL]}
        %             }{\xtrirow
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(1)-Undirected-GaussianLossNoVar}[AR(1) | GNV]}
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(2)-Undirected-GaussianLossNoVar}[AR(2) | GNV]}
        %                 {\xanim|6|{Results/Periodic/Space/AutoregressiveModel-AR(3)-Undirected-GaussianLossNoVar}[AR(3) | GNV]}
        %             }
        %         }{\xdicol
        %             {\xtrirow
        %                 {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(1)-Undirected-GaussianLoss}[AR(1) | GL]}
        %                 {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(2)-Undirected-GaussianLoss}[AR(2) | GL]}
        %                 {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(3)-Undirected-GaussianLoss}[AR(3) | GL]}
        %             }{\xtrirow
        %                 {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(1)-Undirected-GaussianLossNoVar}[AR(1) | GNV]}
        %                 {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(2)-Undirected-GaussianLossNoVar}[AR(2) | GNV]}
        %                 {\xanim{Results/Periodic/Train/AutoregressiveModel-AR(3)-Undirected-GaussianLossNoVar}[AR(3) | GNV]}
        %             }
        %         }
        % \end{figure}

    \subsection{Comparison}
    
        \xfig[H]{\ximg[width=0.55\textwidth]{Results/Static/AUC-Undirected-NL}[Static Data | Test | U | K(2) | NL]}
        \xfig[H]{\ximg[width=0.55\textwidth]{Results/Dynamic/AUC-Undirected-GNV}[Dynamic Data | Test | U | K(2) | GNV]}
        \xfig[H]{\ximg[width=0.55\textwidth]{Results/Periodic/AUC-Undirected-GL}[Periodic Data | Test | U | K(2) | GL]}
    
\section{EU Email Data}
    
    Results are only shown for the dataset spanning the first 200 time steps $[0-200)$ since the second segment $[200-400)$ produces very similar results. The edges (links) between nodes are depicted only for link probabilities higher than 1\% in terms of two-dimensional latent positions and 2.5\% for three dimensions to reduce clutter in the animations. As before, a higher link probability results in a darker edge, being able to get a sense of distances between nodes in three-dimensional plots as well.

    \subsection{Undirected}
    
        % The link probabilities for undirected networks are much lower in general,  
        The undirected latent space representation makes no distinction between senders and receivers, assuming reciprocity, such that if user $i$ is likely to send an email to user $j$, then $j$ is equally likely to send one back to $i$. This is not necessarily a valid assumption, which will be reflected by the performance of the undirected models.
    
            \xfig[H]{\xdouble
                {\ximg{Results/EUEmail0-200/Proba/StaticModel-AR(1)-Undirected-K(2)-NL}[LSM | U | K(2) | NL]}
                {\ximg{Results/EUEmail0-200/Proba/StaticModel-AR(1)-Undirected-K(3)-NL}[LSM | U | K(3) | NL]}
            }\xfig[H]{\xdouble
                {\xanim|9|{Results/EUEmail0-200/Proba/DiffusionModel-AR(1)-Undirected-K(2)-GL-1}[DFM | U | K(2) | GL]}
                {\xanim|9|{Results/EUEmail0-200/Proba/DiffusionModel-AR(1)-Undirected-K(3)-GL-1}[DFM | U | K(3) | GL]}
            }\xfig[H]{\xdouble
                {\xanim|9|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(1)-Undirected-K(2)-GL-1}[AR(1) | U | K(2) | GL]}
                {\xanim|9|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(1)-Undirected-K(3)-GL-1}[AR(1) | U | K(3) | GL]}
            }\xfig[H]{\xdouble
                {\xanim|9|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(3)-Undirected-K(2)-GL-1}[AR(3) | U | K(2) | GL]}
                {\xanim|9|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(3)-Undirected-K(3)-GL-1}[AR(3) | U | K(3) | GL]}
            }\xfig[H]{\xdouble
                {\xanim|9|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(7)-Undirected-K(2)-GL-1}[AR(7) | U | K(2) | GL]}
                {\xanim|9|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(7)-Undirected-K(3)-GL-1}[AR(7) | U | K(3) | GL]}
            }

    \newpage
    \subsection{Directed}
    
        The directed latent space representation shows each user as both a sender (blue) and a receiver (orange), where links only occur between sender-receiver pairs. Doing so allows the modeling of a user's sending and receiving activity separately, in case some users frequently send emails without receiving any, or the other way around. 
        Due to the size of the network and the huge amount of links, the latent space is only visualized every tenth time step. This can be a bit deceptive, as autoregressive processes tend to repeat a pattern with a frequency corresponding to their order. Hence, detailed animations are included in a separate appendix, with latent space representations for LL and GNV penalties as well.
    
            \xfig[H]{\xdouble
                {\ximg{Results/EUEmail0-200/Proba/StaticModel-AR(1)-Directed-K(2)-NL}[LSM | D | K(2) | NL]}
                {\ximg{Results/EUEmail0-200/Proba/StaticModel-AR(1)-Directed-K(3)-NL}[LSM | D | K(3) | NL]}
            }\xfig[H]{\xdouble
                {\xanim|6|{Results/EUEmail0-200/Proba/DiffusionModel-AR(1)-Directed-K(2)-GL-1}[DFM | D | K(2) | GL]}
                {\xanim|6|{Results/EUEmail0-200/Proba/DiffusionModel-AR(1)-Directed-K(3)-GL-1}[DFM | D | K(3) | GL]}
            }\xfig[H]{\xdouble
                {\xanim|6|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(1)-Directed-K(2)-GL-1}[AR(1) | D | K(2) | GL]}
                {\xanim|6|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(1)-Directed-K(3)-GL-1}[AR(1) | D | K(3) | GL]}
            }\xfig[H]{\xdouble
                {\xanim|6|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(3)-Directed-K(2)-GL-1}[AR(3) | D | K(2) | GL]}
                {\xanim|6|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(3)-Directed-K(3)-GL-1}[AR(3) | D | K(3) | GL]}
            }\xfig[H]{\xdouble
                {\xanim|6|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(7)-Directed-K(2)-GL-1}[AR(7) | D | K(2) | GL]}
                {\xanim|6|{Results/EUEmail0-200/Proba/AutoregressiveModel-AR(7)-Directed-K(3)-GL-1}[AR(7) | D | K(3) | GL]}
            }

    \subsection{Comparison}
        
        \xfig[H]{\xdouble
            {\ximg{Results/EUEmail0-200/AUC-Undirected-K(2)-GL}[Test | U | K(2) | GL]}
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(2)-GL}[Test | D | K(2) | GL]}
        }\xfig[H]{\xdouble
            {\ximg{Results/EUEmail0-200/AUC-Undirected-K(3)-GL}[Test | U | K(3) | GL]}
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(3)-GL}[Test | D | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\ximg{Results/EUEmail0-200/AUC-Undirected-K(10)-GL}[Test | U | K(10) | GL]}
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(10)-GL}[Test | D | K(10) | GL]}
        }\xfig[H]{\xdouble
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(2)-LL}[Test | D | K(2) | LL]}
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(2)-GNV}[Test | D | K(2) | GNV]}
        }\xfig[H]{\xdouble
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(3)-LL}[Test | D | K(3) | LL]}
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(3)-GNV}[Test | D | K(3) | GNV]}
        }\xfig[H]{\xdouble
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(10)-LL}[Test | D | K(10) | LL]}
            {\ximg{Results/EUEmail0-200/AUC-Directed-K(10)-GNV}[Test | D | K(10) | GNV]}
        }

    % \subsection{EU Email 200-400}
    
    %     \xfig[H]{\xdicol
    %         {\xdouble
    %             {\ximg{Results/EUEmail200-400/Proba/StaticModel-AR(1)-Directed-K(2)-NL}[LSM | K(2) | NL]}
    %             {\ximg{Results/EUEmail200-400/Proba/StaticModel-AR(1)-Directed-K(3)-NL}[LSM | K(3) | NL]}
    %         }{\xdouble
    %             {\xanim|6|{Results/EUEmail200-400/Proba/DiffusionModel-AR(1)-Directed-K(2)-GL-1}[DFM | K(2) | GL]}
    %             {\xanim|6|{Results/EUEmail200-400/Proba/DiffusionModel-AR(1)-Directed-K(3)-GL-1}[DFM | K(3) | GL]}
    %         }
    %     }
    
    %     \xfig[H]{\xtricol
    %         {\xdouble
    %             {\xanim|6|{Results/EUEmail200-400/Proba/AutoregressiveModel-AR(1)-Directed-K(2)-GL-1}[AR(1) | K(2) | GL]}
    %             {\xanim|6|{Results/EUEmail200-400/Proba/AutoregressiveModel-AR(1)-Directed-K(3)-GL-1}[AR(1) | K(3) | GL]}
    %         }{\xdouble
    %             {\xanim|6|{Results/EUEmail200-400/Proba/AutoregressiveModel-AR(3)-Directed-K(2)-GL-1}[AR(3) | K(2) | GL]}
    %             {\xanim|6|{Results/EUEmail200-400/Proba/AutoregressiveModel-AR(3)-Directed-K(3)-GL-1}[AR(3) | K(3) | GL]}
    %         }{\xdouble
    %             {\xanim|6|{Results/EUEmail200-400/Proba/AutoregressiveModel-AR(7)-Directed-K(2)-GL-1}[AR(7) | K(2) | GL]}
    %             {\xanim|6|{Results/EUEmail200-400/Proba/AutoregressiveModel-AR(7)-Directed-K(3)-GL-1}[AR(7) | K(3) | GL]}
    %         }
    %     }
        
    %     \xfig[H]{\xtricol
    %         {\ximg[width=0.6\textwidth]{Results/EUEmail200-400/AUC-Directed-K(2)-GL}[K(2) | GL | Test]}
    %         {\ximg[width=0.6\textwidth]{Results/EUEmail200-400/AUC-Directed-K(3)-GL}[K(3) | GL | Test]}
    %         {\ximg[width=0.6\textwidth]{Results/EUEmail200-400/AUC-Directed-K(10)-GL}[K(10) | GL | Test]}
    %     }
    
\newpage
\section{UC Messaging Data}

    Results are shown for the dataset spanning the last 120 time steps $[75-195)$, whereas results for the whole sequence is shown in the separate appendix. The network is much sparser than the EU email dataset, resulting in lower link probabilities overall. Links are only depicted for link probabilities of at least 1\%, such that many of the latent spaces appear completely without edges, especially in terms of undirected models.

    \subsection{Undirected}
    
        Undirected models produce much lower link probabilities in general, which most likely relates to the assumption of reciprocity.
    
        \xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/Proba/StaticModel-AR(1)-Undirected-K(2)-NL}[LSM | U | K(2) | NL]}
            {\ximg{Results/UCMessaging75-195/Proba/StaticModel-AR(1)-Undirected-K(3)-NL}[LSM | U | K(3) | NL]}
        }\xfig[H]{\xdouble
            {\xanim|9|{Results/UCMessaging75-195/Proba/DiffusionModel-AR(1)-Undirected-K(2)-GL-1}[DFM | U | K(2) | GL]}
            {\xanim|9|{Results/UCMessaging75-195/Proba/DiffusionModel-AR(1)-Undirected-K(3)-GL-1}[DFM | U | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|9|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(1)-Undirected-K(2)-GL-1}[AR(1) | U | K(2) | GL]}
            {\xanim|9|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(1)-Undirected-K(3)-GL-1}[AR(1) | U | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|9|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(3)-Undirected-K(2)-GL-1}[AR(3) | U | K(2) | GL]}
            {\xanim|9|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(3)-Undirected-K(3)-GL-1}[AR(3) | U | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|9|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(7)-Undirected-K(2)-GL-1}[AR(7) | U | K(2) | GL]}
            {\xanim|9|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(7)-Undirected-K(3)-GL-1}[AR(7) | U | K(3) | GL]}
        }
    
    \newpage
    \subsection{Directed}
    
        Without the reciprocal assumption in directed networks, sender-receiver pairs are allowed a much higher link probability, as a high $\sub(p)(ji)$ does not follow from a high $\sub(p)$. Representing each observation as separate sender and receiver nodes also allows grouping of same type nodes, where several sender nodes can be stacked without having an effect on their relationship.
    
        \xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/Proba/StaticModel-AR(1)-Directed-K(2)-NL}[LSM | D | K(2) | NL]}
            {\ximg{Results/UCMessaging75-195/Proba/StaticModel-AR(1)-Directed-K(3)-NL}[LSM | D | K(3) | NL]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/UCMessaging75-195/Proba/DiffusionModel-AR(1)-Directed-K(2)-GL-1}[DFM | D | K(2) | GL]}
            {\xanim|6|{Results/UCMessaging75-195/Proba/DiffusionModel-AR(1)-Directed-K(3)-GL-1}[DFM | D | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(1)-Directed-K(2)-GL-1}[AR(1) | D | K(2) | GL]}
            {\xanim|6|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(1)-Directed-K(3)-GL-1}[AR(1) | D | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(3)-Directed-K(2)-GL-1}[AR(3) | D | K(2) | GL]}
            {\xanim|6|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(3)-Directed-K(3)-GL-1}[AR(3) | D | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\xanim|6|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(7)-Directed-K(2)-GL-1}[AR(7) | D | K(2) | GL]}
            {\xanim|6|{Results/UCMessaging75-195/Proba/AutoregressiveModel-AR(7)-Directed-K(3)-GL-1}[AR(7) | D | K(3) | GL]}
        }

% \xfig[H]{
%     \xdicol{
%         % \xdicol
%         % {\xdouble
%             % {\ximg{Results/UCMessaging/AUC-Directed-K(10)-NL-Train}[K(10) | NL | Train]}
%             % {\ximg{Results/UCMessaging/AUC-Directed-K(10)-NL}[K(10) | NL | Test]}
%         % }{
%         \xdouble
%             {\ximg{Results/UCMessaging/AUC-Directed-K(10)-GL-Train}[K(10) | GL | Train]}
%             {\ximg{Results/UCMessaging/AUC-Directed-K(10)-GL}[K(10) | GL | Test]}
%         % }%
%     }{%
%         \xdicol
%         {\xdouble
%             {\ximg{Results/UCMessaging/AUC-Directed-K(10)-LL-Train}[K(10) | LL | Train]}
%             {\ximg{Results/UCMessaging/AUC-Directed-K(10)-LL}[K(10) | LL | Test]}
%         }{\xdouble
%             {\ximg{Results/UCMessaging/AUC-Directed-K(10)-GNV-Train}[K(10) | GNV | Train]}
%             {\ximg{Results/UCMessaging/AUC-Directed-K(10)-GNV}[K(10) | GNV | Test]}
%         }%
%     }%
% }%
    
    \subsection{Comparison}
        
        \xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/AUC-Undirected-K(2)-GL}[Test | U | K(2) | GL]}
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(2)-GL}[Test | D | K(2) | GL]}
        }\xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/AUC-Undirected-K(3)-GL}[Test | U | K(3) | GL]}
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(3)-GL}[Test | D | K(3) | GL]}
        }\xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/AUC-Undirected-K(10)-GL}[Test | U | K(10) | GL]}
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(10)-GL}[Test | D | K(10) | GL]}
        }\xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(2)-LL}[Test | D | K(2) | LL]}
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(2)-GNV}[Test | D | K(2) | GNV]}
        }\xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(3)-LL}[Test | D | K(3) | LL]}
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(3)-GNV}[Test | D | K(3) | GNV]}
        }\xfig[H]{\xdouble
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(10)-LL}[Test | D | K(10) | LL]}
            {\ximg{Results/UCMessaging75-195/AUC-Directed-K(10)-GNV}[Test | D | K(10) | GNV]}
        }
