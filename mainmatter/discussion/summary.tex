\section{Summary}

The results of the previous chapter are summarized, starting with the synthetic data. The synthetic data are easily compared based on latent space positions, knowing the underlying network representation. The goal is to show that the models are able to learn the true structure by mimicking the positions from which the links are drawn.

The real-life networks have no predetermined positions, and there are infinitely many compositions giving the exact same link probabilities. Hence, the models are compared solely based on the test AUC scores.

\subsection{Synthetic Data}

    The synthetic datasets show how the latent models are capable of learning the underlying network structure, including the benefits of advanced dynamic models. Knowing that the diffusion added in the synthetic datasets follow a Gaussian distribution, the LL diffusion penalty corresponding to a Laplace distribution is not considered.
    
    \subsubsection{Static Data}
    
        The static data represent a non-temporal network, where the naive approach of simply using the same latent positions for all time steps excels. The dynamic models are trained using no diffusion penalty, similar to the static latent space model. Considering that the dataset includes no diffusion, penalizing diffusion immensely would likely produce better results, however this is done to emphasize the difference between the static and dynamic models.
        
        The true underlying network representation achieves an AUC score of 91\%, with the static latent space model at 90\%, followed by the dynamic models at 87-88\%. Now why is the true representation unable to achieve a score of 100\%? This is because the true positions are only used to derive a set of link probabilities, from which the links in the static dataset are drawn. This is why it is necessary to compare the trained models with the true model, representing the highest possible score a model can achieve.
    
    \subsubsection{Dynamic Data}
    
        Considering that the underlying true network simulates a diffusion process, the dataset is first analyzed in terms of the diffusion model, using different diffusion penalties. Looking at the convergence animations on \cpageref{Results/Dynamic/Train/DiffusionModel-AR(1)-Undirected-NoLoss}, a few observations are made. Firstly, using no diffusion penalty results in overfitting, where there is a large deviation in score from training data to test data. Secondly, the Gaussian cost function penalizes diffusion to such a degree that the underlying movement is not learned. As a result, the Gaussian penalty without a variance parameter provides the best fit, achieving a balance between too much and too little diffusion.
        
        The true representation achieves an AUC score of 92\%, followed by the diffusion model at 90\%. The autoregressive models are quite capable of capturing the dynamicity of the data, however with a slightly more complicated pattern, resulting in scores at 87-89\%. The static latent space model struggles with the temporal change, such that the learned latent space is a mixture of the true initial and final positions, with a score of 84\%. 
    
    \subsubsection{Periodic Data}
    
        The periodic dataset is the one that truly separates the autoregressive models, having three sets of positions rotating in a periodic fashion. Similar to the dynamic data, the convergence of the AR(3) model is depicted on \cpageref{Results/Periodic/Train/AutoregressiveModel-AR(3)-Undirected-NoLoss}. Recall that autoregressive models are optimized using the warm start principle (cf. \cref{sec:pyimpl-positions}), which is quite apparent in the animations. The Gaussian penalty produces accurate results, both with and without a variance parameter. Given an insignificant superiority of 0.1\%, the penalty with the variance parameter is chosen for comparison.
        
        Looking at the ROC curves in \Cref{Results/Periodic/AUC-Undirected-GL}, it really shows that the DFM and LSM are in fact AR(1) models with and without diffusion, respectively. The true representation obtains a score of 90\%, followed by the AR(3) model at 89\%, the AR(2) model at 80\% and finally the AR(1) models at 68-69\%. The AR(2) model achieves a much higher score than the AR(1) models, being able to model two sets of positions, opposed to only one.
    
\subsection{Synthetic AR(2) Data}

    Several experiments have been conducted with synthetic AR(2) datasets, as the second order autoregressive process in theory is capable of modeling velocity, acceleration and curvature. This included datasets with clusters forming new clusters, and even with a cluster moving across a grid of nodes. 
    Velocity is modeled as constant change in latent positions between time steps, using $\bmphi=[2,-1]$ (for all $k$ dimensions). Doing so adds the difference $\Z_{t-1} - \Z_{t-2}$ to the most recent set of observations $\Z_{t-1}$, corresponding to the autoregressive process shown in \Cref{eq:data-velocity}. The diffusion $\bmepsilon$ is omitted for simplicity.
    \begin{equation}\label{eq:data-velocity}
        \Z_t = 2 \Z_{t-1} - \Z_{t-2} = \Z_{t-1} + (\Z_{t-1} - \Z_{t-2})
    \end{equation}
    The distance between the two sets of initial latent positions then define the magnitude of the change, or simply put, the speed. With minor adjustments to the AR coefficients, the process can model acceleration or curvature instead. However, the difficult part is to learn the exact combination of coefficients and initial positions producing the correct movement. Generating small synthetic networks comprised of only 30 nodes, all attempts have resulted in either a static fit or a dynamic fit to the training data. While this may be due to lack of structure related to the network size, the result poses another issue. There are several combinations of AR coefficients producing an accurate fit to the training data, without generalizing to the test data. 
    This raises a question of whether or not modeling velocity, acceleration and curvature is feasible in practice, and a more thorough analysis must be carried out.

\subsection{EU Email Data}

    Not knowing the underlying network structure, it is difficult to distinguish between a good and bad latent representation. Fortunately, the ROC curves are quite transparent, showing the AUC score of each individual model. Comparing undirected and directed models using Gaussian penalty, the undirected models produce slightly better results for $k=2$, while the directed AR models improve a lot (5\% increase) by adding another dimension. Using ten-dimensional latent positions, both the undirected and directed models perform equally well, with scores as high as 97-98\%, indicating that the assumption of reciprocity holds. The significant performance increase from two to three dimensions gives reason to believe that the directed models are capable of reaching their full potential at a lower $k$ than the undirected models. This could be analyzed further.
    
    Inspecting the results using LL and GNV penalties, the scores for K(2) suggests that the directed GL models are not fully converged, despite several reruns. Besides the K(2) results, the performance for K(3) and K(10) are quite similar, with a slight edge to GL in terms of K(3) and LL in terms of K(10). However, the differences are not large enough to draw a conclusion on which penalty is superior. A more surprising result, is the fact that the static latent space model performs as well as, or even slightly better than the dynamic models. This is in spite of the distinct periodic pattern related to weekdays and weekends, for which the AR(7) model captures no additional information. 
    
    It is important to note that there is a huge difference between predicting the number of links present at each time step, and predicting exactly which of the thousand actors are linked at which time. The first problem would be readily solved by the AR(7) model, while the static LSM is apparently just as suited to solve the second problem. This raises a question of whether or not the autoregressive processes are simply modeling a static snapshot, disregarding rotation, reflection and scaling.
    
\subsection{UC Messaging Data}

    The first observation that can be made, is the distinct performance difference between the undirected and directed models. The scores differ with approximately 3-10\%, 4-5\% and 2-4\% for K(2), K(3) and K(10), respectively, in favor of the directed models. 
    Higher dimensionality compensates for the largest differences, however the results give reason to believe that the network is less reciprocal than the EU email network.
    Experiments with even higher values of $k$ should be conducted to see whether the differences diminish completely given sufficient latent dimensions.
    
    Another observation is that the dynamic models are able to achieve slightly higher scores than the static LSM, especially in terms of the directed diffusion model. More surprisingly, the two-dimensional DFM achieves the overall highest AUC score of 93\%, followed closely by other DFM variants and a few AR models. This indicates that there is in fact additional information to be retrieved using a dynamic model, but also that the information is simply diffusion.
    
    Due to the vast amount of different models, each model has been limited to three reruns, which seems to be not enough in many cases. For instance, the AR(7) model achieves an AUC score of 92\% for (D | K(2) | LL), while the other dynamic models achieves scores of 85-86\%. To verify that all models' full potential have been reached, several more reruns should be executed.
    
    Accounting for score deviations as a result of random initialization and other random factors, the use of different diffusion penalties do not pose a significant impact. Furthermore, considering that the dataset include only the last 120 time steps, many of the two thousand actors are likely never linked, which could be removed for a simpler analysis.
